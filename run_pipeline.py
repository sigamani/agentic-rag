import json
from pathlib import Path
import os
from tools.data_tools import create_db
from tools.table_tools import extract_table_summary
from tools.qa_tools import compute_qa_answer

try:
    from langsmith import traceable
except ImportError:
    def traceable(func): return func

@traceable
def run_pipeline(source_path: str):
    correct, total, failed, skipped = 0, 0, 0, 0
    with open(source_path, "r") as f:
        data = json.load(f)
    for idx, sample in enumerate(data):
        if "qa" not in sample or "program" not in sample["qa"]:
            print(f"â­ï¸ Skipping sample {idx} â€” missing 'qa' or 'qa.program'")
            skipped += 1
            continue

        total += 1
        print(f"\nğŸ” Evaluating sample {idx+1}: {sample['qa']['question']}")

        result_2 = extract_table_summary.invoke({"sample": sample})
        result_3 = compute_qa_answer.invoke({"sample": sample})
        predicted = result_3.get("predicted_answer")
        expected = sample["qa"]["answer"]

        if predicted == expected:
            correct += 1
            print("âœ… Answer correct")
        else:
            failed += 1
            print(f"âŒ Mismatch: predicted={predicted} | expected={expected}")

        create_db.invoke({"input_data": {**result_3, "table_summary": result_2.get("summary", [])}})

    print("\nğŸ“Š Final Evaluation Summary")
    print(f"âœ… Correct: {correct}")
    print(f"âŒ Incorrect: {failed}")
    print(f"â­ï¸ Skipped: {skipped}")
    print(f"ğŸ“¦ Total Evaluated: {total}")
    print(f"ğŸ“ˆ Accuracy: {round((correct / total) * 100, 2) if total else 0}%")

if __name__ == "__main__":
    run_pipeline("train_turn_small.json")

